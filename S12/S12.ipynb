{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:lrtest.lr_finder:To enable mixed precision training, please install `apex`. Or you can re-install this package by the following command:\n  pip install torch-lr-finder -v --global-option=\"amp\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "from read_inputs import read_transform_inputs\n",
    "from utility_fun import *\n",
    "import matplotlib.pyplot as plt\n",
    "from gradcam.visualize import VisualizeCam\n",
    "from train import *\n",
    "from lrtest.lr_range_test import LRRangeFinder\n",
    "from lrtest.lr_cycle_plot import LRCyclePlot\n",
    "from torch.optim import lr_scheduler\n",
    "from model.model import BasicBlock,Bottleneck,ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"D:\\\\Assignment_ML_Engineer\\\\EVA_4.0\\\\S12\\\\data\\\\tiny-imagenet-200\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tin_val_folder_structure(path,\n",
    "                                       images_folder='images',\n",
    "                                       annotations_file='val_annotations.txt'):\n",
    "    # Check if files/annotations are still there to see\n",
    "    # if we already run reorganize the folder structure.\n",
    "    images_folder = os.path.join(path, images_folder)\n",
    "    annotations_file = os.path.join(path, annotations_file)\n",
    "\n",
    "    # Exists\n",
    "    if not os.path.exists(images_folder) \\\n",
    "       and not os.path.exists(annotations_file):\n",
    "        if not os.listdir(path):\n",
    "            raise RuntimeError('Validation folder is empty.')\n",
    "        return\n",
    "\n",
    "    # Parse the annotations\n",
    "    with open(annotations_file) as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            img = values[0]\n",
    "            label = values[1]\n",
    "            img_file = os.path.join(images_folder, values[0])\n",
    "            label_folder = os.path.join(path, label)\n",
    "            os.makedirs(label_folder, exist_ok=True)\n",
    "            try:\n",
    "                shutil.move(img_file, os.path.join(label_folder, img))\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "\n",
    "    #os.sync()\n",
    "    assert not os.listdir(images_folder)\n",
    "    shutil.rmtree(images_folder)\n",
    "    os.remove(annotations_file)\n",
    "    #os.sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize_tin_val_folder_structure(path = \"D:\\\\Assignment_ML_Engineer\\\\EVA_4.0\\\\S12\\\\data\\\\tiny-imagenet-200\\\\val\",images_folder = 'images',annotations_file='val_annotations.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = { 'train': transforms.Compose([transforms.RandomHorizontalFlip(),transforms.ToTensor()]),\n",
    "                    'val'  : transforms.Compose([transforms.ToTensor(),]) }\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=128, shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "            Conv2d-3           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 64, 64]             128\n",
      "            Conv2d-5           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
      "        BasicBlock-7           [-1, 64, 64, 64]               0\n",
      "            Conv2d-8           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
      "           Conv2d-10           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 64, 64]             128\n",
      "       BasicBlock-12           [-1, 64, 64, 64]               0\n",
      "           Conv2d-13          [-1, 128, 32, 32]          73,728\n",
      "      BatchNorm2d-14          [-1, 128, 32, 32]             256\n",
      "           Conv2d-15          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 32, 32]             256\n",
      "           Conv2d-17          [-1, 128, 32, 32]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 32, 32]             256\n",
      "       BasicBlock-19          [-1, 128, 32, 32]               0\n",
      "           Conv2d-20          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 32, 32]             256\n",
      "           Conv2d-22          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 32, 32]             256\n",
      "       BasicBlock-24          [-1, 128, 32, 32]               0\n",
      "           Conv2d-25          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-26          [-1, 256, 16, 16]             512\n",
      "           Conv2d-27          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-28          [-1, 256, 16, 16]             512\n",
      "           Conv2d-29          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-30          [-1, 256, 16, 16]             512\n",
      "       BasicBlock-31          [-1, 256, 16, 16]               0\n",
      "           Conv2d-32          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-33          [-1, 256, 16, 16]             512\n",
      "           Conv2d-34          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-35          [-1, 256, 16, 16]             512\n",
      "       BasicBlock-36          [-1, 256, 16, 16]               0\n",
      "           Conv2d-37            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-38            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-39            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-40            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-41            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-42            [-1, 512, 8, 8]           1,024\n",
      "       BasicBlock-43            [-1, 512, 8, 8]               0\n",
      "           Conv2d-44            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-45            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-46            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-47            [-1, 512, 8, 8]           1,024\n",
      "       BasicBlock-48            [-1, 512, 8, 8]               0\n",
      "           Linear-49                  [-1, 200]         102,600\n",
      "================================================================\n",
      "Total params: 11,271,432\n",
      "Trainable params: 11,271,432\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 45.00\n",
      "Params size (MB): 43.00\n",
      "Estimated Total Size (MB): 88.05\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, [2, 2, 2, 2]).to(device)\n",
    "show_model_summary(model, input_size=(3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=0.02, steps_per_epoch=len(trainloader),\n",
    "                       epochs=30, div_factor=10, final_div_factor=10,\n",
    "                       pct_start=10/30)\n",
    "trainloader = dataloaders['train']\n",
    "testloader = dataloaders['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch [0] train accuracy 0.110 : test accuracy 0.106\n",
      "epoch [1] train accuracy 0.168 : test accuracy 0.161\n",
      "epoch [2] train accuracy 0.225 : test accuracy 0.210\n",
      "epoch [3] train accuracy 0.263 : test accuracy 0.249\n",
      "epoch [4] train accuracy 0.297 : test accuracy 0.280\n",
      "epoch [5] train accuracy 0.336 : test accuracy 0.310\n",
      "epoch [6] train accuracy 0.366 : test accuracy 0.331\n",
      "epoch [7] train accuracy 0.391 : test accuracy 0.352\n",
      "epoch [8] train accuracy 0.412 : test accuracy 0.366\n",
      "epoch [9] train accuracy 0.441 : test accuracy 0.384\n",
      "epoch [10] train accuracy 0.459 : test accuracy 0.400\n",
      "epoch [11] train accuracy 0.482 : test accuracy 0.413\n",
      "epoch [12] train accuracy 0.505 : test accuracy 0.431\n",
      "epoch [13] train accuracy 0.522 : test accuracy 0.435\n",
      "epoch [14] train accuracy 0.543 : test accuracy 0.450\n",
      "epoch [15] train accuracy 0.560 : test accuracy 0.460\n",
      "epoch [16] train accuracy 0.574 : test accuracy 0.461\n",
      "epoch [17] train accuracy 0.598 : test accuracy 0.468\n",
      "epoch [18] train accuracy 0.610 : test accuracy 0.475\n",
      "epoch [19] train accuracy 0.636 : test accuracy 0.485\n",
      "epoch [20] train accuracy 0.648 : test accuracy 0.480\n",
      "epoch [21] train accuracy 0.660 : test accuracy 0.482\n",
      "epoch [22] train accuracy 0.679 : test accuracy 0.479\n",
      "epoch [23] train accuracy 0.704 : test accuracy 0.491\n",
      "epoch [24] train accuracy 0.720 : test accuracy 0.488\n",
      "epoch [25] train accuracy 0.734 : test accuracy 0.485\n",
      "epoch [26] train accuracy 0.754 : test accuracy 0.487\n",
      "epoch [27] train accuracy 0.768 : test accuracy 0.486\n",
      "epoch [28] train accuracy 0.789 : test accuracy 0.487\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7c5cc4a9e763>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0ml1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3e-6\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0ml2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Assignment_ML_Engineer\\EVA_4.0\\S12\\train.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = training_class(model = model,trainloader = trainloader, testloader = testloader, device = device, epoch= 30, optimizer = optimizer, criterion = criterion ,l1 = 3e-6 , l2 = 1e-3,scheduler=scheduler)\n",
    "train_acc,test_acc = clf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test Loop\n",
    "testloss,test_check =  truth_checker(model, testloader, device,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}